{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scenario\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from constants import DATA_ENTITIES_DIR, DATA_HAZARDS_DIR, DATA_TEMP_DIR, REQUIREMENTS_DIR\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from climada.engine import CostBenefit, Impact, ImpactCalc\n",
    "from climada.engine.cost_benefit import risk_aai_agg, risk_rp_100, risk_rp_250\n",
    "from climada.entity import DiscRates, Entity, Exposures, LitPop\n",
    "from climada.entity.impact_funcs import ImpactFunc, ImpactFuncSet, ImpfTropCyclone\n",
    "from climada.entity.impact_funcs.storm_europe import ImpfStormEurope\n",
    "from climada.entity.impact_funcs.trop_cyclone import ImpfSetTropCyclone\n",
    "from climada.entity.measures import Measure, MeasureSet\n",
    "from climada.hazard import Hazard\n",
    "from climada.util.api_client import Client\n",
    "\n",
    "from costben.costben_handler import CostBenefitHandler\n",
    "from entity.entity_handler import EntityHandler\n",
    "from exposure.exposure_handler import ExposureHandler\n",
    "from hazard.hazard_handler import HazardHandler\n",
    "from impact.impact_handler import ImpactHandler\n",
    "\n",
    "from base_handler import BaseHandler\n",
    "from logger_config import LoggerConfig\n",
    "\n",
    "logger = LoggerConfig(logger_types=[\"file\"])\n",
    "\n",
    "base_handler = BaseHandler()\n",
    "costben_handler = CostBenefitHandler()\n",
    "entity_handler = EntityHandler()\n",
    "exposure_handler = ExposureHandler()\n",
    "hazard_handler = HazardHandler()\n",
    "impact_handler = ImpactHandler()\n",
    "\n",
    "\n",
    "# Available Exposure data types in CLIMADA API for Egypt/Thailand: ['litpop']\n",
    "# Available Hazard data types in CLIMADA API for Egypt/Thailand: ['river_flood', 'wildfire', 'earthquake', flood, 'tropical_cyclone']\n",
    "# Available climate scenarios for hazard type river_flood/tropical_c in country Egypt/Thailand: ['rcp26', 'historical', 'rcp60', 'rcp85']\n",
    "# Available time horizons for hazard type river_flood in country Egypt: ['2030_2050', '1980_2000', '2070_2090', '2010_2030', '2050_2070']\n",
    "\n",
    "country_name = \"Egypt\"\n",
    "exposure_type = \"litpop\"  # Available exposure types for Egypt/Thailand: ['litpop']\n",
    "hazard_type = \"river_flood\"  # Available hazard types for Egypt/Thailand: ['river_flood', 'wildfire', 'earthquake', 'flood', 'tropical_cyclone']\n",
    "scenario = \"rcp26\"  # Available scenarios for Egypt/Thailand: ['rcp26', 'historical', 'rcp60', 'rcp85']\n",
    "time_horizon = \"2030_2050\"  # Available time horizons for Egypt/Thailand: ['2030_2050', '1980_2000', '2070_2090', '2010_2030', '2050_2070']\n",
    "annual_growth = 1.01\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# const exposureNonEconomicDict = {\n",
    "#   thailand: [\"tree_crops_farmers\", \"grass_crops_farmers\", \"buddhist_monks\", \"water_users\", \"roads\", \"students\"],\n",
    "#   egypt: [\"hospitalised_people\", \"students\", \"diarrhea_patients\", \"roads\"],\n",
    "# };\n",
    "\n",
    "# const exposureEconomicDict = {\n",
    "#   thailand: [\"tree_crops\", \"grass_crops\", \"wet_markets\"],\n",
    "#   egypt: [\"crops\", \"livestock\", \"power_plants\", \"hotels\"],\n",
    "# };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import rasterio\n",
    "\n",
    "def read_mat():\n",
    "    with h5py.File(DATA_HAZARDS_DIR / \"hazard_D_THA_rcp45.mat\", 'r') as f:\n",
    "        # Print all items in the root\n",
    "        print(\"Items in the root:\", list(f.keys()))\n",
    "\n",
    "        # Access the 'hazard' group/dataset\n",
    "        hazard = f['hazard']\n",
    "        print(\"Items in 'hazard':\", list(hazard.keys()))\n",
    "\n",
    "        # If 'hazard' contains further groups or datasets, access them\n",
    "        for item in hazard:\n",
    "            print(f\"Exploring {item}:\")\n",
    "            data = hazard[item]\n",
    "            \n",
    "            # Check if this is a dataset or a group\n",
    "            if isinstance(data, h5py.Dataset):\n",
    "                print(f\"Dataset {item} found with shape {data.shape} and data type {data.dtype}\")\n",
    "            else:\n",
    "                print(f\"Group {item} contains: {list(data.keys())}\")\n",
    "\n",
    "            # If the item is stored by reference (common in MATLAB structures)\n",
    "            if data.dtype == 'O':  # Object references\n",
    "                # This will go through each reference and try to resolve it\n",
    "                for ref in data:\n",
    "                    referenced_object = f[data[ref][0]]  # Access by reference\n",
    "                    print(f\"Referenced object for {ref}: {referenced_object.shape}\")\n",
    "\n",
    "                    # Optionally, you can load the data into an array or similar\n",
    "                    # print(np.array(referenced_object))\n",
    "\n",
    "def read_tif():\n",
    "    with rasterio.open(DATA_HAZARDS_DIR / \"hazard_HW_EGY_rcp45.tif\") as src:\n",
    "        print(f'Number of bands: {src.count}')\n",
    "        # Loop through each band\n",
    "        # for i in range(1, src.count + 1):\n",
    "        #     band = src.read(i)\n",
    "        #     print(band)\n",
    "        #     meta = src.tags(i)\n",
    "        #     print(f'  Metadata for Band {i}: {meta}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Drought App\n",
    "entity_present = entity_handler.get_entity_from_xlsx(\n",
    "    DATA_ENTITIES_DIR / \"3_entity_TODAY_THAI_D_USD_1_cal_python - Calibrated.xlsx\"\n",
    ")\n",
    "entity_present.check()\n",
    "entity_present.exposures.ref_year = 2024\n",
    "\n",
    "entity_future = entity_handler.get_future_entity(entity_present, 2050, 0.0294)\n",
    "entity_future.check()\n",
    "\n",
    "\n",
    "hazard_present = Hazard().from_hdf5(DATA_HAZARDS_DIR / \"Hazard_DR_present_Thailand.h5\")\n",
    "hazard_present.haz_type = \"D\"\n",
    "hazard_present.check()\n",
    "\n",
    "hazard_future = Hazard().from_hdf5(DATA_HAZARDS_DIR / \"Hazard_RCP45.h5\")\n",
    "hazard_future.haz_type = \"D\"\n",
    "hazard_future.check()\n",
    "\n",
    "hazard_present.units = \"SPI\"\n",
    "hazard_future.units = \"SPI\"\n",
    "\n",
    "hazard_present.centroids.set_geometry_points()\n",
    "hazard_future.centroids.set_geometry_points()\n",
    "\n",
    "hazard_present.intensity_thres = -4\n",
    "hazard_future.intensity_thres = -4\n",
    "\n",
    "\n",
    "# Calculate impact\n",
    "impact_present = ImpactCalc(\n",
    "    entity_present.exposures, entity_present.impact_funcs, hazard_present\n",
    ").impact(save_mat=True)\n",
    "impact_future = ImpactCalc(\n",
    "    entity_future.exposures, entity_future.impact_funcs, hazard_future\n",
    ").impact(save_mat=True)\n",
    "\n",
    "\n",
    "costben = costben_handler.calculate_cost_benefit(\n",
    "    hazard_present, entity_present, hazard_future, entity_future, 2050\n",
    ")\n",
    "# costben_handler.plot_cost_benefit(costben)\n",
    "# costben_handler.plot_waterfall(\n",
    "#     costben, hazard_present, entity_present, hazard_future, entity_future\n",
    "# )\n",
    "\n",
    "# exposure_handler.generate_exposure_geojson(entity_future.exposures, \"Thailand\")\n",
    "# hazard_handler.generate_hazard_geojson(hazard_future, \"Thailand\")\n",
    "# impact_handler.generate_impact_geojson(impact_future, \"Thailand\")\n",
    "ax = costben.plot_waterfall(hazard_present, entity_present, hazard_future, entity_future\n",
    ")\n",
    "# costben.plot_arrow_averted(ax)\n",
    "# costben.plot_event_view((10, 15))\n",
    "# costben.plot_waterfall_accumulated(hazard_present, entity_present, entity_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_risk = risk_aai_agg(impact_present)\n",
    "print(f\"Risk 2024: {curr_risk}\")\n",
    "\n",
    "fut_risk = risk_aai_agg(impact_future)\n",
    "print(f\"Risk 2050: {fut_risk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Drought Climada\n",
    "# Set present Entity\n",
    "entity_present = Entity.from_excel(\n",
    "    DATA_ENTITIES_DIR / \"entity_TODAY_THA_D_tree_crops.xlsx\"\n",
    ")\n",
    "# Set exposure ref year\n",
    "entity_present.exposures.ref_year = 2024\n",
    "entity_present.check()\n",
    "\n",
    "# Set future Entity\n",
    "entity_future = deepcopy(entity_present)\n",
    "entity_future.exposures.ref_year = 2050\n",
    "growth = 0.029\n",
    "entity_future.exposures.gdf[\"value\"] = entity_future.exposures.gdf.value.values * (1 + growth) ** (\n",
    "    entity_future.exposures.ref_year - entity_present.exposures.ref_year\n",
    ")\n",
    "entity_future.check()\n",
    "\n",
    "# Set present Hazard\n",
    "hazard_present = Hazard.from_mat(\n",
    "    DATA_HAZARDS_DIR / \"hazard_D_THA_historical.mat\",\n",
    ")\n",
    "hazard_present.units = \"m\"\n",
    "hazard_present.centroids.set_geometry_points()\n",
    "hazard_present.intensity_thres = -4\n",
    "hazard_present.check()\n",
    "\n",
    "# Set future hazard\n",
    "hazard_future = Hazard.from_raster(\n",
    "    DATA_HAZARDS_DIR / \"hazard_HW_EGY_rcp45.tif\",\n",
    "    attrs={\n",
    "        \"frequency\": np.array([0.5, 0.2, 0.1, 0.04]),\n",
    "        \"event_id\": np.array([1, 2, 3, 4]),\n",
    "        \"units\": \"number of days\",\n",
    "    },\n",
    "    haz_type=\"HW\",\n",
    "    band=[1, 2, 3, 4],\n",
    ")\n",
    "hazard_future.units = \"number of days\"\n",
    "hazard_future.centroids.set_geometry_points()\n",
    "hazard_future.intensity_thres = 0\n",
    "hazard_future.check()\n",
    "\n",
    "# Calculate impact\n",
    "impact_present = ImpactCalc(\n",
    "    entity_present.exposures, entity_present.impact_funcs, hazard_present\n",
    ").impact()\n",
    "impact_future = ImpactCalc(\n",
    "    entity_future.exposures, entity_future.impact_funcs, hazard_future\n",
    ").impact()\n",
    "\n",
    "# Calculate cost-benefit\n",
    "cost_benefit = CostBenefit()\n",
    "cost_benefit.calc(\n",
    "    hazard=hazard_present,\n",
    "    entity=entity_present,\n",
    "    haz_future=hazard_future,\n",
    "    ent_future=entity_future,\n",
    "    risk_func=risk_aai_agg,\n",
    "    save_imp=True,\n",
    ")\n",
    "\n",
    "# Plot cost benefit waterfall\n",
    "axis = cost_benefit.plot_waterfall(\n",
    "    hazard_present,\n",
    "    entity_present,\n",
    "    hazard_future,\n",
    "    entity_future,\n",
    "    risk_func=risk_aai_agg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Flood Egypt App\n",
    "entity_present = entity_handler.get_entity_from_xlsx(\n",
    "    DATA_ENTITIES_DIR / \"entity_TODAY_EGY_FL_crops.xlsx\"\n",
    ")\n",
    "entity_present.check()\n",
    "entity_present.exposures.ref_year = 2024\n",
    "\n",
    "entity_future = entity_handler.get_future_entity(entity_present, 2050, 0.04)\n",
    "entity_future.check()\n",
    "\n",
    "\n",
    "hazard_present = hazard_handler.get_hazard(\n",
    "    hazard_type=\"flood\", filepath=DATA_HAZARDS_DIR / \"hazard_FL_EGY_historical.tif\"\n",
    ")\n",
    "hazard_present.haz_type = \"FL\"\n",
    "hazard_present.check()\n",
    "\n",
    "hazard_future = hazard_handler.get_hazard(\n",
    "    hazard_type=\"flood\", filepath=DATA_HAZARDS_DIR / \"hazard_FL_EGY_rcp26.tif\"\n",
    ")\n",
    "hazard_future.haz_type = \"FL\"\n",
    "hazard_future.check()\n",
    "\n",
    "hazard_present.units = \"m\"\n",
    "hazard_future.units = \"m\"\n",
    "\n",
    "hazard_present.centroids.set_geometry_points()\n",
    "hazard_future.centroids.set_geometry_points()\n",
    "\n",
    "hazard_present.intensity_thres = 0\n",
    "hazard_future.intensity_thres = 0\n",
    "\n",
    "\n",
    "# Calculate impact\n",
    "impact_present = ImpactCalc(\n",
    "    entity_present.exposures, entity_present.impact_funcs, hazard_present\n",
    ").impact(save_mat=True)\n",
    "impact_future = ImpactCalc(\n",
    "    entity_future.exposures, entity_future.impact_funcs, hazard_future\n",
    ").impact(save_mat=True)\n",
    "\n",
    "\n",
    "# costben = costben_handler.calculate_cost_benefit(\n",
    "#     hazard_present, entity_present, hazard_future, entity_future, 2050\n",
    "# )\n",
    "# costben_handler.plot_cost_benefit(costben)\n",
    "# costben_handler.plot_waterfall(\n",
    "#     costben, hazard_present, entity_present, hazard_future, entity_future\n",
    "# )\n",
    "\n",
    "# exposure_handler.generate_exposure_geojson(entity_future.exposures, \"Thailand\")\n",
    "# hazard_handler.generate_hazard_geojson(hazard_future, \"Thailand\")\n",
    "# impact_handler.generate_impact_geojson(impact_future, \"Thailand\")\n",
    "# ax = costben.plot_waterfall(hazard_present, entity_present, hazard_future, entity_future)\n",
    "# costben.plot_arrow_averted(ax)\n",
    "# costben.plot_event_view((10, 15))\n",
    "# costben.plot_waterfall_accumulated(hazard_present, entity_present, entity_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(impact_future.imp_mat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example heatwaves Thailand App\n",
    "entity_present = entity_handler.get_entity_from_xlsx(\n",
    "    DATA_ENTITIES_DIR / \"entity_TODAY_THA_HW_buddhist_monks.xlsx\"\n",
    ")\n",
    "entity_present.check()\n",
    "entity_present.exposures.ref_year = 2024\n",
    "\n",
    "entity_future = entity_handler.get_future_entity(entity_present, 2050, 0.0294)\n",
    "entity_future.check()\n",
    "\n",
    "\n",
    "hazard_present = hazard_handler.get_hazard(\n",
    "    hazard_type=\"flood\", filepath=DATA_HAZARDS_DIR / \"hazard_FL_EGY_historical.tif\"\n",
    ")\n",
    "hazard_present.haz_type = \"FL\"\n",
    "hazard_present.check()\n",
    "\n",
    "# hazard_future = hazard_handler.get_hazard(\n",
    "#     hazard_type=\"flood\", filepath=DATA_HAZARDS_DIR / \"hazard_FL_EGY_historical.tif\"\n",
    "# )\n",
    "# hazard_future.haz_type = \"D\"\n",
    "# hazard_future.check()\n",
    "\n",
    "hazard_present.units = \"SPI\"\n",
    "# hazard_future.units = \"SPI\"\n",
    "\n",
    "hazard_present.centroids.set_geometry_points()\n",
    "# hazard_future.centroids.set_geometry_points()\n",
    "\n",
    "hazard_present.intensity_thres = -4\n",
    "# hazard_future.intensity_thres = -4\n",
    "\n",
    "\n",
    "# Calculate impact\n",
    "impact_present = ImpactCalc(\n",
    "    entity_present.exposures, entity_present.impact_funcs, hazard_present\n",
    ").impact(save_mat=True)\n",
    "# impact_future = ImpactCalc(\n",
    "#     entity_future.exposures, entity_future.impact_funcs, hazard_future\n",
    "# ).impact(save_mat=True)\n",
    "\n",
    "\n",
    "costben = costben_handler.calculate_cost_benefit(\n",
    "    hazard_present, entity_present, None, None, None\n",
    ")\n",
    "costben_handler.plot_cost_benefit(costben)\n",
    "# costben_handler.plot_waterfall(\n",
    "#     costben, hazard_present, entity_present, hazard_future, entity_future\n",
    "# )\n",
    "\n",
    "# exposure_handler.generate_exposure_geojson(entity_future.exposures, \"Thailand\")\n",
    "# hazard_handler.generate_hazard_geojson(hazard_future, \"Thailand\")\n",
    "# impact_handler.generate_impact_geojson(impact_future, \"Thailand\")\n",
    "# ax = costben.plot_waterfall(hazard_present, entity_present, hazard_future, entity_future)\n",
    "# costben.plot_arrow_averted(ax)\n",
    "# costben.plot_event_view((10, 15))\n",
    "# costben.plot_waterfall_accumulated(hazard_present, entity_present, entity_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5 , 0.2 , 0.1 , 0.04])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazard_future.frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    6.637424\n",
      "dtype: float32\n",
      "2    13.274847\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(hazard_future.intensity.toarray().T, columns=[2, 5, 10, 25])\n",
    "(df != 0).sum()\n",
    "\n",
    "df2 = pd.DataFrame(df[2])\n",
    "print(df2.max())\n",
    "df2 = df2/0.5\n",
    "print(df2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp2</th>\n",
       "      <th>rp5</th>\n",
       "      <th>rp10</th>\n",
       "      <th>rp25</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rp2_level</th>\n",
       "      <th>rp5_level</th>\n",
       "      <th>rp10_level</th>\n",
       "      <th>rp25_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4456174.84</td>\n",
       "      <td>4456174.84</td>\n",
       "      <td>4456174.84</td>\n",
       "      <td>4456174.84</td>\n",
       "      <td>POINT (30.81570 30.73167)</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2399419.80</td>\n",
       "      <td>2399419.80</td>\n",
       "      <td>2399419.80</td>\n",
       "      <td>2399419.80</td>\n",
       "      <td>POINT (30.76508 30.71227)</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359231.35</td>\n",
       "      <td>359231.35</td>\n",
       "      <td>359231.35</td>\n",
       "      <td>359231.35</td>\n",
       "      <td>POINT (30.82678 30.68094)</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254021.86</td>\n",
       "      <td>254021.86</td>\n",
       "      <td>254021.86</td>\n",
       "      <td>254021.86</td>\n",
       "      <td>POINT (30.76721 30.65817)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541649.87</td>\n",
       "      <td>541649.87</td>\n",
       "      <td>541649.87</td>\n",
       "      <td>541649.87</td>\n",
       "      <td>POINT (30.83119 30.65875)</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>118871.66</td>\n",
       "      <td>118871.66</td>\n",
       "      <td>118871.66</td>\n",
       "      <td>118871.66</td>\n",
       "      <td>POINT (30.79380 30.65125)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61429.74</td>\n",
       "      <td>61429.74</td>\n",
       "      <td>61429.74</td>\n",
       "      <td>61429.74</td>\n",
       "      <td>POINT (30.79871 30.61375)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>333774.05</td>\n",
       "      <td>333774.05</td>\n",
       "      <td>333774.05</td>\n",
       "      <td>333774.05</td>\n",
       "      <td>POINT (30.80356 30.58251)</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>187394.00</td>\n",
       "      <td>187394.00</td>\n",
       "      <td>187394.00</td>\n",
       "      <td>187394.00</td>\n",
       "      <td>POINT (30.81873 30.57864)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>552530.39</td>\n",
       "      <td>552530.39</td>\n",
       "      <td>552530.39</td>\n",
       "      <td>552530.39</td>\n",
       "      <td>POINT (30.82669 30.51888)</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>744431.48</td>\n",
       "      <td>744431.48</td>\n",
       "      <td>744431.48</td>\n",
       "      <td>744431.48</td>\n",
       "      <td>POINT (30.80580 30.52451)</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6795889.15</td>\n",
       "      <td>30815490.98</td>\n",
       "      <td>48985618.33</td>\n",
       "      <td>73005220.15</td>\n",
       "      <td>POINT (30.93240 30.29500)</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>168940.66</td>\n",
       "      <td>766049.76</td>\n",
       "      <td>1217745.36</td>\n",
       "      <td>1814854.47</td>\n",
       "      <td>POINT (30.84499 30.44466)</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15647.41</td>\n",
       "      <td>15647.41</td>\n",
       "      <td>15647.41</td>\n",
       "      <td>15647.41</td>\n",
       "      <td>POINT (31.06004 30.21546)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10075.68</td>\n",
       "      <td>10075.68</td>\n",
       "      <td>10075.68</td>\n",
       "      <td>10075.68</td>\n",
       "      <td>POINT (30.72451 28.22983)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>97931.77</td>\n",
       "      <td>97931.77</td>\n",
       "      <td>97931.77</td>\n",
       "      <td>97931.77</td>\n",
       "      <td>POINT (32.88242 24.13028)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rp2          rp5         rp10         rp25  \\\n",
       "0   4456174.84   4456174.84   4456174.84   4456174.84   \n",
       "1   2399419.80   2399419.80   2399419.80   2399419.80   \n",
       "2    359231.35    359231.35    359231.35    359231.35   \n",
       "3    254021.86    254021.86    254021.86    254021.86   \n",
       "4    541649.87    541649.87    541649.87    541649.87   \n",
       "5    118871.66    118871.66    118871.66    118871.66   \n",
       "6     61429.74     61429.74     61429.74     61429.74   \n",
       "7    333774.05    333774.05    333774.05    333774.05   \n",
       "8    187394.00    187394.00    187394.00    187394.00   \n",
       "9    552530.39    552530.39    552530.39    552530.39   \n",
       "10   744431.48    744431.48    744431.48    744431.48   \n",
       "11  6795889.15  30815490.98  48985618.33  73005220.15   \n",
       "12   168940.66    766049.76   1217745.36   1814854.47   \n",
       "13    15647.41     15647.41     15647.41     15647.41   \n",
       "14    10075.68     10075.68     10075.68     10075.68   \n",
       "15    97931.77     97931.77     97931.77     97931.77   \n",
       "\n",
       "                     geometry  rp2_level  rp5_level  rp10_level  rp25_level  \n",
       "0   POINT (30.81570 30.73167)          5          5           5           5  \n",
       "1   POINT (30.76508 30.71227)          5          5           5           5  \n",
       "2   POINT (30.82678 30.68094)          3          3           3           3  \n",
       "3   POINT (30.76721 30.65817)          3          2           2           2  \n",
       "4   POINT (30.83119 30.65875)          4          3           3           3  \n",
       "5   POINT (30.79380 30.65125)          2          2           2           2  \n",
       "6   POINT (30.79871 30.61375)          1          1           1           1  \n",
       "7   POINT (30.80356 30.58251)          3          3           3           3  \n",
       "8   POINT (30.81873 30.57864)          3          2           2           2  \n",
       "9   POINT (30.82669 30.51888)          4          4           4           4  \n",
       "10  POINT (30.80580 30.52451)          4          4           4           4  \n",
       "11  POINT (30.93240 30.29500)          5          5           5           5  \n",
       "12  POINT (30.84499 30.44466)          2          4           4           4  \n",
       "13  POINT (31.06004 30.21546)          1          1           1           1  \n",
       "14  POINT (30.72451 28.22983)          1          1           1           1  \n",
       "15  POINT (32.88242 24.13028)          1          1           1           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_impact_geojson(\n",
    "    impact: Impact,\n",
    "    country_name: str,\n",
    "    return_periods: tuple = (25, 20, 15, 10),\n",
    "    asset_type: str = \"economic\",\n",
    "    exposure_type: str = None,\n",
    "):\n",
    "    try:\n",
    "        country_iso3 = base_handler.get_iso3_country_code(country_name)\n",
    "        admin_gdf = base_handler.get_admin_data(country_iso3, 2)\n",
    "        coords = np.array(impact.coord_exp)\n",
    "        local_exceedance_imp = impact.local_exceedance_imp(return_periods)\n",
    "        local_exceedance_imp = pd.DataFrame(local_exceedance_imp).T\n",
    "        data = np.column_stack((coords, local_exceedance_imp))\n",
    "        columns = [\"latitude\", \"longitude\"] + [f\"rp{rp}\" for rp in return_periods]\n",
    "\n",
    "        impact_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Round the rp values based on the asset_type\n",
    "        if asset_type == \"economic\":\n",
    "            impact_df.update(impact_df[[f\"rp{rp}\" for rp in return_periods]].round(2))\n",
    "        elif asset_type == \"non_economic\":\n",
    "            impact_df.update(impact_df[[f\"rp{rp}\" for rp in return_periods]].apply(np.ceil))\n",
    "\n",
    "        geometry = [Point(xy) for xy in zip(impact_df[\"longitude\"], impact_df[\"latitude\"])]\n",
    "        impact_gdf = gpd.GeoDataFrame(impact_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "        # Filter impact_gdf to exclude rows where all return period values are zero\n",
    "        impact_gdf = impact_gdf[\n",
    "            (impact_gdf[[f\"rp{rp}\" for rp in return_periods]] != 0).any(axis=1)\n",
    "        ]\n",
    "        impact_gdf = impact_gdf.drop(columns=[\"latitude\", \"longitude\"])\n",
    "        impact_gdf = impact_gdf.reset_index(drop=True)\n",
    "\n",
    "        # Calculate percentiles for each return period\n",
    "        percentile_values = {}\n",
    "        percentiles = (20, 40, 60, 80)\n",
    "        for rp in return_periods:\n",
    "            rp_data = impact_gdf[f\"rp{rp}\"]\n",
    "            percentile_values[f\"rp{rp}\"] = np.percentile(rp_data, percentiles).round(1).tolist()\n",
    "            percentile_values[f\"rp{rp}\"].insert(0, 0)\n",
    "\n",
    "        # Assign levels based on the percentile values\n",
    "        impact_gdf = impact_handler.assign_levels(impact_gdf, percentile_values)\n",
    "        # Spatial join with administrative areas\n",
    "        joined_gdf = gpd.sjoin(impact_gdf, admin_gdf, how=\"left\", predicate=\"within\")\n",
    "        # TODO: Test if this needs to be refined\n",
    "        joined_gdf = joined_gdf[~joined_gdf[\"country\"].isna()]\n",
    "\n",
    "\n",
    "        radius = impact_handler.get_circle_radius(impact.haz_type, country_iso3, exposure_type)\n",
    "        # Convert to GeoJSON for this layer and add to all_layers_geojson\n",
    "        impact_geojson = joined_gdf.__geo_interface__\n",
    "        impact_geojson[\"_metadata\"] = {\n",
    "            \"percentile_values\": percentile_values,\n",
    "            \"radius\": radius,\n",
    "            \"return_periods\": return_periods,\n",
    "            \"title\": f\"Risk ({impact.unit})\",\n",
    "            \"unit\": impact.unit,\n",
    "        }\n",
    "\n",
    "        # Save the combined GeoJSON file\n",
    "        # map_data_filepath = DATA_TEMP_DIR / \"risks_geodata.json\"\n",
    "        # with open(map_data_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        #     json.dump(impact_geojson, f)\n",
    "        return impact_geojson\n",
    "    except Exception as exception:\n",
    "        print(\"error\", f\"An unexpected error occurred. More info: {exception}\")\n",
    "\n",
    "\n",
    "generate_impact_geojson(impact_future, 'egypt', (2, ), \"economic\", \"crops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm_values(value):\n",
    "    norm_fact = 1.\n",
    "    norm_name = ''\n",
    "    if value / 1.0e9 > 1:\n",
    "        norm_fact = 1.0e9\n",
    "        norm_name = 'bn'\n",
    "    elif value / 1.0e6 > 1:\n",
    "        norm_fact = 1.0e6\n",
    "        norm_name = 'm'\n",
    "    elif value / 1.0e3 > 1:\n",
    "        norm_fact = 1.0e3\n",
    "        norm_name = 'k'\n",
    "    return norm_fact, norm_name\n",
    "\n",
    "\n",
    "def test():\n",
    "    axis=None\n",
    "    if entity_future.exposures.ref_year == entity_present.exposures.ref_year:\n",
    "        raise ValueError('Same reference years for future and present entities.')\n",
    "    present_year = entity_present.exposures.ref_year\n",
    "    future_year = entity_future.exposures.ref_year\n",
    "\n",
    "    imp = ImpactCalc(entity_present.exposures, entity_present.impact_funcs, hazard_present)\\\n",
    "            .impact(assign_centroids=hazard_present.centr_exp_col not in entity_present.exposures.gdf)\n",
    "    curr_risk = risk_aai_agg(imp)\n",
    "\n",
    "    imp = ImpactCalc(entity_future.exposures, entity_future.impact_funcs, hazard_future)\\\n",
    "            .impact(assign_centroids=hazard_present.centr_exp_col not in entity_future.exposures.gdf)\n",
    "    fut_risk = risk_aai_agg(imp)\n",
    "\n",
    "    if not axis:\n",
    "        _, axis = plt.subplots(1, 1)\n",
    "    norm_fact, norm_name = _norm_values(curr_risk)\n",
    "\n",
    "    # current situation\n",
    "    print('Risk at {:d}: {:.3e}'.format(present_year, curr_risk))\n",
    "\n",
    "    # changing future\n",
    "    # socio-economic dev\n",
    "    imp = ImpactCalc(entity_future.exposures, entity_future.impact_funcs, hazard_present)\\\n",
    "            .impact(assign_centroids=False)\n",
    "    risk_dev = risk_aai_agg(imp)\n",
    "    print('Risk with development at {:d}: {:.3e}'.format(future_year, risk_dev))\n",
    "\n",
    "    # socioecon + cc\n",
    "    print('Risk with development and climate change at {:d}: {:.3e}'.\n",
    "                format(future_year, fut_risk))\n",
    "\n",
    "    axis.bar(1, curr_risk / norm_fact)\n",
    "    axis.text(1, curr_risk / norm_fact, str(int(round(curr_risk / norm_fact))),\n",
    "                horizontalalignment='center', verticalalignment='bottom',\n",
    "                fontsize=12, color='k')\n",
    "    axis.bar(2, height=(risk_dev - curr_risk) / norm_fact,\n",
    "                bottom=curr_risk / norm_fact)\n",
    "    axis.text(2, curr_risk / norm_fact + (risk_dev - curr_risk) / norm_fact / 2,\n",
    "                str(int(round((risk_dev - curr_risk) / norm_fact))),\n",
    "                horizontalalignment='center', verticalalignment='center', fontsize=12, color='k')\n",
    "    axis.bar(3, height=(fut_risk - risk_dev) / norm_fact,\n",
    "                bottom=risk_dev / norm_fact)\n",
    "    axis.text(3, risk_dev / norm_fact + (fut_risk - risk_dev) / norm_fact / 2,\n",
    "                str(int(round((fut_risk - risk_dev) / norm_fact))),\n",
    "                horizontalalignment='center', verticalalignment='center', fontsize=12,\n",
    "                color='k')\n",
    "    axis.bar(4, height=fut_risk / norm_fact)\n",
    "    axis.text(4, fut_risk / norm_fact, str(int(round(fut_risk / norm_fact))),\n",
    "                horizontalalignment='center', verticalalignment='bottom',\n",
    "                fontsize=12, color='k')\n",
    "\n",
    "    axis.set_xticks(np.arange(4) + 1)\n",
    "    axis.set_xticklabels(['Risk ' + str(present_year),\n",
    "                            'Economic \\ndevelopment',\n",
    "                            'Climate \\nchange',\n",
    "                            'Risk ' + str(future_year)])\n",
    "    axis.set_ylabel('Impact (' + imp.unit + ' ' + norm_name + ')')\n",
    "    axis.set_title('Risk at {:d} and {:d}'.format(present_year, future_year))\n",
    "    return axis\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List DataTypeInfos\n",
    "data_type_infos = client.list_data_type_infos()\n",
    "exposure_data_types = [\n",
    "    data_type_info.data_type\n",
    "    for data_type_info in data_type_infos\n",
    "    if data_type_info.data_type_group == \"exposures\"\n",
    "]\n",
    "hazard_data_types = [\n",
    "    data_type_info.data_type\n",
    "    for data_type_info in data_type_infos\n",
    "    if data_type_info.data_type_group == \"hazard\"\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Available Exposure data types in CLIMADA API for all countries:\\n{exposure_data_types}\")\n",
    "print(\n",
    "    f\"Available Hazard data types in CLIMADA API for all countries:\\n{hazard_data_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available country Exposures and Hazard data types\n",
    "dataset_infos = client.list_dataset_infos(\n",
    "    properties={\n",
    "        \"country_name\": country_name,\n",
    "    }\n",
    ")\n",
    "\n",
    "exposure_data_types = list(\n",
    "    set(\n",
    "        [\n",
    "            dataset_info.data_type.data_type\n",
    "            for dataset_info in dataset_infos\n",
    "            if dataset_info.data_type.data_type_group == \"exposures\"\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "hazard_data_types = list(\n",
    "    set(\n",
    "        [\n",
    "            dataset_info.data_type.data_type\n",
    "            for dataset_info in dataset_infos\n",
    "            if dataset_info.data_type.data_type_group == \"hazard\"\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Available Exposure data types in CLIMADA API for {country_name}: {exposure_data_types}\")\n",
    "print(\n",
    "    f\"Available Hazard data types in CLIMADA API for {country_name}: {hazard_data_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available climate scenarios and time horizons for specific hazard type in countries Thailand and Egypt\n",
    "if hazard_type == \"river_flood\" or \"wildfire\":\n",
    "    available_scenarios = list(\n",
    "        set(\n",
    "            [\n",
    "                dataset_info.properties[\"climate_scenario\"]\n",
    "                for dataset_info in dataset_infos\n",
    "                if dataset_info.data_type.data_type == hazard_type\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    available_time_horizons = list(\n",
    "        set(\n",
    "            [\n",
    "                dataset_info.properties[\"year_range\"]\n",
    "                for dataset_info in dataset_infos\n",
    "                if dataset_info.data_type.data_type == hazard_type\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "if hazard_type == \"tropical_cyclone\":\n",
    "    available_scenarios = list(\n",
    "        set(\n",
    "            [\n",
    "                dataset_info.properties[\"climate_scenario\"]\n",
    "                for dataset_info in dataset_infos\n",
    "                if dataset_info.data_type.data_type == hazard_type\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    available_time_horizons = list(\n",
    "        set(\n",
    "            [\n",
    "                dataset_info.properties.get(\"ref_year\")\n",
    "                for dataset_info in dataset_infos\n",
    "                if dataset_info.data_type.data_type == hazard_type\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "if hazard_type == \"earthquake\":\n",
    "    available_scenarios = []\n",
    "    available_time_horizons = []\n",
    "if hazard_type == \"flood\":\n",
    "    available_scenarios = []\n",
    "    available_time_horizons = list(\n",
    "        set(\n",
    "            [\n",
    "                dataset_info.properties[\"year_range\"]\n",
    "                for dataset_info in dataset_infos\n",
    "                if dataset_info.data_type.data_type == hazard_type\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Available climate scenarios for hazard type {hazard_type} in country {country_name}: {available_scenarios}\"\n",
    ")\n",
    "print(\n",
    "    f\"Available time horizons for hazard type {hazard_type} in country {country_name}: {available_time_horizons}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available country Hazard DatasetInfos\n",
    "hazard_dataset_infos = client.list_dataset_infos(\n",
    "    properties={\n",
    "        \"data_type\": \"river_flood\",\n",
    "        \"country_name\": \"Thailand\",\n",
    "        \"climate_scenario\": \"rcp26\",\n",
    "        \"year_range\": \"2030_2050\",\n",
    "    }\n",
    ")\n",
    "hazard_dataset_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Exposure\n",
    "# Available Exposures: ['litpop']\n",
    "exposure_present = exposure_handler.get_exposure(country_name)\n",
    "if annual_growth > 1:\n",
    "    exposure_future = exposure_handler.get_growth_exposure(\n",
    "        exposure_present, annual_growth, 2040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hazard\n",
    "# Available Hazards: ['river_flood', 'tropical_cyclone', 'wildfire', 'flood', 'earthquake']\n",
    "hazard_present = hazard_handler.get_hazard(\n",
    "    hazard_type,\n",
    "    \"historical\",\n",
    "    \"1980_2000\",\n",
    "    country_name,\n",
    ")\n",
    "\n",
    "if scenario != \"historical\":\n",
    "    hazard_future = hazard_handler.get_hazard(\n",
    "        hazard_type,\n",
    "        scenario,\n",
    "        time_horizon,\n",
    "        country_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Impact\n",
    "impact_function_set = impact_handler.calculate_impact_function_set(hazard_present)\n",
    "impact_present = impact_handler.calculate_impact(exposure_present, hazard_present, impact_function_set)\n",
    "\n",
    "if scenario != \"historical\":\n",
    "    if annual_growth > 1:\n",
    "        impact_future = impact_handler.calculate_impact(\n",
    "            exposure_future, hazard_future, impact_function_set)\n",
    "    impact_future = impact_handler.calculate_impact(\n",
    "        exposure_present, hazard_future, impact_function_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_set = costben_handler.get_measure_set_from_excel('RF')\n",
    "discount_rates = costben_handler.get_discount_rates_from_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "class DataFrameSQLite:\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "\n",
    "    def save_dataframe(self, df, table_name):\n",
    "        \"\"\"\n",
    "        Save a DataFrame to the SQLite database.\n",
    "        \n",
    "        :param df: DataFrame to save.\n",
    "        :param table_name: Name of the table to save the DataFrame to.\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "            print(f\"DataFrame saved to {table_name} table.\")\n",
    "\n",
    "    def read_dataframe(self, table_name):\n",
    "        \"\"\"\n",
    "        Read a DataFrame from the SQLite database.\n",
    "        \n",
    "        :param table_name: Name of the table to read the DataFrame from.\n",
    "        :return: DataFrame read from the database.\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "        return df\n",
    "\n",
    "# Example usage\n",
    "db_path = 'my_data.db'  # Path to your SQLite database file\n",
    "df_sqlite = DataFrameSQLite(db_path)\n",
    "\n",
    "# Assuming you have a DataFrame `df` to save\n",
    "df_sqlite.save_dataframe(exp_gdf, 'exposure')\n",
    "\n",
    "# To read the saved DataFrame from the database\n",
    "df_read = df_sqlite.read_dataframe('exposure')\n",
    "print(df_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class ExcelToSQLite:\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "\n",
    "    def read_excel_to_df(self, excel_path, sheet_name):\n",
    "        \"\"\"Reads a specified sheet from an Excel file into a DataFrame.\"\"\"\n",
    "        return pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "\n",
    "    def adjust_df_columns(self, df, columns_to_keep=None):\n",
    "        \"\"\"Adjusts DataFrame columns based on the provided list. If None, keeps all columns.\"\"\"\n",
    "        if columns_to_keep is not None:\n",
    "            df = df[columns_to_keep]\n",
    "        return df\n",
    "\n",
    "    def save_df_to_sqlite(self, df, table_name):\n",
    "        \"\"\"Saves a DataFrame to an SQLite table, appending data if the table already exists.\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            df.to_sql(table_name, conn, if_exists=\"append\", index=False)\n",
    "\n",
    "    def read_table(self, table_name):\n",
    "        \"\"\"Reads a table from SQLite database into a DataFrame.\"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            return pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "db_path = \"climadera.db\"  # Path to your SQLite database file\n",
    "excel_path = DATA_ENTITIES_DIR / \"3_entity_TODAY_THAI_D_USD_1_modified.xlsx\"  # Path to your Excel file\n",
    "excel_to_sqlite = ExcelToSQLite(db_path)\n",
    "\n",
    "# Define the sheets and corresponding table names\n",
    "sheets_tables = {\n",
    "    \"assets\": \"exposures\",\n",
    "    \"impact_functions\": \"impact_functions\",\n",
    "    \"measures\": \"measures\",\n",
    "    \"discount\": \"discount_rates\",\n",
    "    \"names\": \"names\",\n",
    "}\n",
    "\n",
    "# Iterate over sheets and tables, read, adjust (if needed), and save to SQLite\n",
    "for sheet, table in sheets_tables.items():\n",
    "    df = excel_to_sqlite.read_excel_to_df(excel_path, sheet)\n",
    "\n",
    "    # Here you can define which columns to keep for each table if needed, e.g.:\n",
    "    # if table == 'exposures':\n",
    "    #     columns_to_keep = ['Column1', 'Column2']\n",
    "    #     df = excel_to_sqlite.adjust_df_columns(df, columns_to_keep)\n",
    "    # else:\n",
    "    #     df = excel_to_sqlite.adjust_df_columns(df)\n",
    "\n",
    "    excel_to_sqlite.save_df_to_sqlite(df, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class ExcelToSQLite:\n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "\n",
    "    def read_excel_and_save(self, excel_path, tabs_columns_mapping):\n",
    "        \"\"\"\n",
    "        Read specified tabs from an Excel file and save them to SQLite database.\n",
    "\n",
    "        :param excel_path: Path to the Excel file.\n",
    "        :param tabs_columns_mapping: Dict mapping tab names to their columns adjustments.\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            for tab, columns in tabs_columns_mapping.items():\n",
    "                df = pd.read_excel(excel_path, sheet_name=tab)\n",
    "\n",
    "                # Adjust columns if specified\n",
    "                if columns:\n",
    "                    df = df[columns]\n",
    "\n",
    "                df.to_sql(tab, conn, if_exists=\"append\", index=False)\n",
    "                print(f\"Data from {tab} tab saved to {tab} table.\")\n",
    "\n",
    "    def read_table(self, table_name):\n",
    "        \"\"\"\n",
    "        Read data from a specified table in the SQLite database.\n",
    "\n",
    "        :param table_name: Name of the table to read data from.\n",
    "        :return: DataFrame with the table data.\n",
    "        \"\"\"\n",
    "        with sqlite3.connect(self.db_path) as conn:\n",
    "            return pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "db_path = \"climadera.db\"  # Path to your SQLite database file\n",
    "excel_path = DATA_ENTITIES_DIR / \"3_entity_TODAY_THAI_D_USD_1_modified.xlsx\"  # Path to your Excel file\n",
    "tabs_columns_mapping = {\n",
    "    \"assets\": None,  # Specify columns as a list if you want to adjust them, or None to include all\n",
    "    \"impact_functions\": None,\n",
    "    \"measures\": None,\n",
    "    \"discount\": None,\n",
    "    \"names\": None,\n",
    "}\n",
    "\n",
    "excel_to_sqlite = ExcelToSQLite(db_path)\n",
    "excel_to_sqlite.read_excel_and_save(excel_path, tabs_columns_mapping)\n",
    "\n",
    "# Reading data from one of the tables\n",
    "df_assets = excel_to_sqlite.read_table(\"assets\")\n",
    "print(df_assets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_unu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
